\cs{need to make clear the diff btw objects meaning the concept and meaning an instance}

Real-world objects, being members of many categories, can be called by many names (e.g.,\ an apple can be called \name{apple, fruit, food} etc.). 
In \langvis research (\lv), the choice of a particular name for an object is a pervasive task---it underlies virtually all tasks which model how speakers use language to refer to objects in the world, such as image description, visual question answering, etc. 
%
\lv methods are generally based on object detection or image classification models (or the visual features extracted from them) which were pre-trained towards predicting the single correct label of objects. The set of labels are often determined rather arbitrarily---it may contain very specific (e.g.,\ \name{goblet, gyromitra}) as well as "basic-level" labels (e.g., \name{bus}) (cf. the inventory of the ILSVRC challenges; \citealt{ILSVRC15}). 

This approach has its justification in that models can learn rich, discriminative visual feature representations which capture fine-grained differences in object appearances (e.g.,\ shape--pointed vs. slightly pointed). 
It is, however, different from predicting the natural name of an object, 
because, as has been found in numerous studies in psychology, humans have a preference towards a particular name (\textit{entry-level name}, e.g.,\ \name{apple}) when naturally calling an object  \cite{rosch1976basic,Rosch1978,jolicoeur1984pictures}. 
Entry-level names have hereby usually been considered to be an attribute of concrete \textit{concepts} (e.g.,\ penguin, duck), where the choice of a concept's entry-level name depends on factors such as its typicality with respect to its basic-level category (bird). \cs{Need to check Jolicoeur and their experiments} 
Crucially, though, as our analysis also shows (ManyNames analysis), human object naming is \textit{instance}-dependent---contextual visual features (see also \citet{graf2016animal}) may humans have choose different names for object instances of the same concrete concept, and have them even disagree in their choice for the same instance \cs{real example here with duck, bird}. 

Despite its relevance in \lv, the challenge of instance-based naming variation has been overseen, and most \lv datasets not necessarily provide enough information to make progress on the problem of modelling natural object naming (they only provide very few names). 
Research that particularly focuses on the prediction of entry-level names is scarce, and existing work has adopted (i) taxonomic view (?) and (ii) developed specialised methods implementing the taxonomic view (?)\cite{Ordonez:2016}. \cs{check paper}

In this paper, we seek an understanding of the notion of entry-level names of instances of real-world objects in images, and address the problem of automatically predicting those. %, i.e.,\ the name that humans naturally prefer to call an object.  
Specifically, and in contrast to previous works, we 
(i) take on an empirical notion of entry-level names, and define it on the instance-level, i.e., the name that humans prefer to use when calling a particular object in a real-world image. 
(ii) examine in how far standard models in computer vision, namely object detection or image classification models, do already learn entry-level names by being trained on images labelled with rather \textit{arbitrary} object names. XXX
For this purpose, we use \mn, a new dataset of real-world images, built on top of \vg, which was  annotated with a large number\ $(36)$ of object names by means of a crowdsourcing study. 

Our contributions are: 
(i) We present our extension of the \mn dataset that augments all collected object names with verification information, which allows an in-depth analysis of naming models on the task of object naming. 
(ii) Theoretical:
(a) We show that entry-level names should be derived on the instance-level as opposed to the XXX level \cs{(TO SHOW: entry-level names are different for the same "class" @Sina) (contrast to psychological studies)}
(b) We need many name annotations to derive the entry-level name (contrast to few annotations in L+V and computer vision; \cs{TO SHOW: entry-level name of an instance varies depending on the number of annotations/instance)}
(iii) Practical:
(a) Object detectors trained on "arbitrary" natural object names do learn entry-level names to some extend (as expected: they learn the shared features leading to entry-level \cs{-- can we show that mistakes are rather class-based? i.e., tendency towards a certain name for each class?)}
(b) To predict entry-level names without annotating a huge amount of training examples, it is possible to fine-tune (iii) on \mn. We show that \cs{(say something about mistakes not made anymore). }

