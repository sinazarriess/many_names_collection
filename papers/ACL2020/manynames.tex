

\cs{@gbt @mw}
\subsection{Overview of ManyNames}
\label{sect:mn_overview}

brief summary of lrec paper, shortcoming, what we added

\subsection{Verification of Annotations}
\label{sect:mn_verification}

@mw

\subsection{Analysis}
\label{sect:mn_analysis}


\paragraph{Of ManyNames:} 
\cs{+ @sz?}\\
\cs{Here goes what has not been discussed in LREC paper, because it focusses on entry-level names. }
\cs{Results aimed to show that we need \underline{multiple} annotations per object \underline{instance} to get the entry-level name}
\begin{itemize}
	\item Statistics wrt entry-level of object class != entry-level of its instances to (i.e.,\ entry-levels cannot be derived on class-level) \gbt{But, what's an object class in our data? We can't really use collection synsets, can we? Those are not really object classes?}
	\item Plot of how most frequent name changes in relation to the number of responses collected (e.g., phase 0 vs. 1 vs. 2 vs. 3). (i.e.,\ entry-level names cannot be derived from a few annotators) \gbt{My guess is that it will be pretty constant the moment you have 9 annotators, as in round 0. Plan: report percentage of overlap with VG name (72\%); if you want, we can estimate something based on the annotated data, but this would be more like sampling from all annotations (randomly sample 1, 2, 3, ... names and see how things change.)}
	\cs{We saw in the pilot that it does change in relation to the number of responses. I think it would be helpful for the whole story if we could show quantitatively that we need many annotations per instance to get a reliable entry-level name (and that this may depend on the domain; that the entry-level is different from the VG name we have already calculated). I would not use the verified data for this, and each round could correspond to a sample, i.e., we draw 9 vs. 18 vs. 17 vs. 36 samples.}
	\item Coverage of set of topN MN names (MN442) wrt all VG objects \cs{@\sz} \gbt{According to my data, there are 415 entry-level names (=entry-level names for canonical object; could extend definition to all objects if need be). Are your 442 names the most frequent names for some image? Else, we could do the experiments with the entry-level names as the vocabulary (but it's probably too late now).}
	\item ...
\end{itemize}


\paragraph{Of Verification Annotations}
\cs{@gbt @mw}
\begin{itemize}
	\item ...
	\item ...
	\item For the instances where VG!=topMN: Percentage of instances where the VG name is among the responses of an \textit{alternative object} (as given by clustering).
\end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "acl2020_main"
%%% End:
