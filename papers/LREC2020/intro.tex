
% SUBMITTED VERSION:
% Generally, research in Language \& Vision (L\&V) is interested in modeling how speakers naturally talk about visual objects and scenes, in contrast to the fixed image labeling schemes used in Computer Vision.
% Data collections in L\&V are typically set up as free annotation tasks,  where subjects are free to produce whatever word or utterance they consider most suitable for the given task (e.g.\ image description, reference to objects, visual dialogue), which naturally results in linguistic variation.
% For this reason, large-scale data collections in L\&V usually provide a certain amount of parallel annotations for the same entity from different annotators \cite{fangetal:2015,devlin:imcaqui,Kazemzadeh2014,mao15,vries2017guesswhat}.

% GBT revision (I've re-organized the material into paragraphs differently and gone more directly to object names):
A central issue in Language \& Vision (L\&V) is how speakers refer to objects. 
This is most prominent for referring expression generation and interpretation [REFS], but it also pervades virtually any other L\&V task, such as caption generation or visual dialogue [REFS].
One of the central components of referring expressions are \textit{object names}; for instance, speakers may name the left object in Figure \ref{fig:cake} `cake', `food', `bread', or `dessert', a.o.
This aspect of reference has been understudied in Computational Linguistics and L\&V; as a consequence, it is not clear to what extent current L\&V models capture human naming behavior.
% the factors affecting the choice of a name are far from clear, as is the potential of current L\&V models to successfully model naming data.

% SUBMITTED VERSION:
% In this paper, we present ManyNames, a dataset with substantial amounts of object names per object for real-world images.
% We start by surveying existing resources in L\&V that provide object names: \refcoco \cite{Yu2016}, a collection of referring expressions, \flickr \cite{plummer2015flickr30kentities}, which provides region-to-phrase linkings for Flickr 30K captions \cite{young:2014}, and \vgenome \cite{krishna2016visualgenome}, which features extensive region-level annotations. We highlight their potential contributions to the study of object naming, and also argue that the low number of annotations per item prevents reliable assessment or linguistic analysis of object-specific preferences and naming variation.
% GBT revision:
In this paper, we present a new dataset, ManyNames, to enable research on both analysis and modeling of human naming behavior. 
We start by surveying existing existing resources in L\&V that provide object names,
assessing their potential to contribute to the study of object naming.
While these resources can be exploited for this area of inquiry to some extent (as detailed in the survey), we argue that the low number of annotations per item prevents reliable assessment of naming preferences, on the one hand, and variation, on the other, which is what we are interested in. 
This motivates the development of ManyNames, as well as our design choices for it. 

% SUBMITTED VERSION:
% Compared to experimental work on perception and language grounding, however, recent data collections in L\&V capture a rather limited amount of inter-speaker variation.
% For instance, picture naming norms used in Psycholinguistics record naming responses for hundreds of speakers for the same object  \cite{snodgrass,rossion2004revisiting}, whereas captioning or referring expression data sets typically provide less than 10 annotations per entity \cite{devlin:imcaqui,Kazemzadeh2014,mao15}.
% Consequently, a reliable assessment of inter-annotator agreement, speaker preferences, and a deeper linguistic analysis of the observed variation is mostly not possible with available data collections in  L\&V.
% At the same time, these datasets have much potential for research on these topics, as they provide more realistic images of real-world objects and scenes than the idealized drawings used in picture naming norms (see Figure \ref{fig:cake}), as well as a wider coverage of object categories.
% A more systematic understanding of the factors influencing the choice of object names could inform theoretical work on language grounding and pragmatics \cite{rohde2012communicating,graf2016animal}, as well as the design of models and architectures (e.g.,~Lazaridou et al.~\shortcite{lazaridou-dinu-baroni:2015:ACL-IJCNLP}; Ordonez et al.,~\shortcite{Ordonez:2016}; Zhao et al.,~\shortcite{zhao2017open}).
ManyNames v.1, the version presented in this paper, contains 36 crowd-sourced names for 25K instances from \vgenome \cite{krishna2016visualgenome}.%
\footnote{Available at \url{https://github.com/amore-upf/manynames}.}
It is inspired in naming norms as developed in Psycholinguistics~\cite{snodgrass,rossion2004revisiting}, which is the field that has devoted the most attention to object naming to date.
ManyNorms is much larger and uses real images of objects in complex visual contexts, in contrast to idealized drawings (Figure \ref{fig:cake}, right), which makes it suitable for research in L\&V.
%Moreover, our images show objects in complex visual contexts,
%unlike the ``clean'' ImageNet data~\cite{imagenet_cvpr09} that is popular in Computer Vision \cite{ILSVRC15}, and %unlike stylized line drawings used in picture naming experiments in Cognitive Science (Figure \ref{fig:cake}).
% Naming norms record naming responses for dozens or hundreds of speakers for the same object.
% Naming norms in Psycholinguistics are typically small (500-1000 images) and use idealized drawings (Figure \ref{fig:cake}, right).
% \gbt{TODO: add footnote with the naming norms that have real images?}
% ManyNames is much larger and, crucially, is based on real images and 
Names are sometimes used as object labels in Computer Vision, in large datasets with real-world images; however, compared to experimental work on perception and language grounding, recent data collections in L\&V capture a rather limited amount of data; for instance, captioning or referring expression data sets typically provide 2-5 annotations per object \cite{devlin:imcaqui,Kazemzadeh2014,mao15}.
\gbt{Is the latter redundant?}

\begin{figure}[tbp]
\scriptsize
\begin{tabular}{p{4.3cm}p{2cm}}
%VisualGenome+ManyNames & \cite{snodgrass}\\
\centering
\includegraphics[scale=0.15]{figures/2390077_1254219_supercat_unique.png} &
\includegraphics[scale=0.4]{figures/snodgrass_vanderwart_cake_042.png}\\
 cake\ (53),  food\ (19), bread\ (8), burger\ (6), dessert\ (6), snacks\ (3), muffin\ (3),  pastry\ (3) & \hspace{.9cm} cake (83)
\end{tabular}
\caption{Names for a cake object in ManyNames (left) and in Snodgrass's Naming Norms (right), percentages of responses in parentheses.}
\label{fig:cake}
\end{figure}

% NEW -- I thought we needed to include this discussion, too.
Object names are rarely used in isolation; typically they are embedded in more complex referring expressions, which are themselves embedded in sentences that are part of discourses or dialogues.
However, in the same way that it has proven useful to model referring expressions in visual scenes in an isolated fashion [REFS], we believe there is value in modeling object names on their own.
Questions that need addressing regarding this topic are 1) what factors drive the choice of a name, 2) how much variation in naming do we find and what factors drive this variation (object category? individual properties of the object? context?), 3) what aspects of naming pose difficulties for models in L\&V.
ManyNames enables research on these questions; here, for reasons of scope and space, we will provide only preliminary results on the amount and type of variation we find in the data. 
ManyNames can also potentially inform theoretical work on language grounding and pragmatics \cite{rohde2012communicating,graf2016animal}, as well as the design of L\&V models and architectures (e.g.,~Lazaridou et al.~\shortcite{lazaridou-dinu-baroni:2015:ACL-IJCNLP}; Ordonez et al.,~\shortcite{Ordonez:2016}; Zhao et al.,~\shortcite{zhao2017open}).

The trends we identify in the dataset are illustrated in Figure \ref{fig:cake} (left): Our data reveals clear naming preferences (in the example, 53\% of the annotators prefer the name \textit{cake}, corresponding to the so-called basic-level category, see Section \ref{subsec:rosch} for further explanation) and also rich variation (the remaining annotators prefer other options like \textit{food, dessert, bread}) that is not restricted to taxonomic relations studied in previous work on naming \cite{Ordonez:2016,graf2016animal}: while \word{food} is in a taxonomic relation to \word{cake} (it is a hypernym), \textit{dessert} highlights a different facet of the object.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "lrec2020naming"
%%% End:
