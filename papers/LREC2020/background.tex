\subsection{Object Naming as a Linguistic Phenomenon}

The act of naming an object amounts to that of picking out a nominal to be employed to refer to it (e.g., ``the \refexp{dog}'', ``the white \refexp{dog} to the left'').
Since an object is simultaneously a member of multiple categories (e.g., a young beagle belongs to the categories \cat{dog}, \cat{beagle}, \cat{animal}, \cat{puppy}, \cat{pet}, etc.), all the various names that lexicalize these constitute a valid alternative, meaning that the same object can be named with different names \cite{brown1958shall,murphy2004big}.

Seminal work on concepts by Rosch inspired a taxonomic view of object naming, in which object names typically exhibit a preferred level of specificity called the ``entry-level'' \cite{jolicoeur1984pictures}. This typically corresponds to an intermediate level of specificity, i.e., basic level (e.g., \refexp{bird}, \refexp{car}; \newcite{rosch1976basic}), as opposed to more generic (e.g., \refexp{animal}, \refexp{vehicle}) or specific categories (e.g., \refexp{sparrow}, \refexp{convertible}). 
However, less prototypical members of basic-level categories tend to be instead identified with sub-level categories (e.g., a penguin is typically called \refexp{penguin} and not \refexp{bird}) \cite{jolicoeur1984pictures}. 
%This out-of-context preference towards a certain taxonomic level is often referred to as \textbf{lexical availability}. 
While the traditional notion of entry-level categories suggests that objects tend to be named by a \refexp{single} preferred concept, research on pragmatics has found that speakers are flexible in their choice of the level of specificity.
Scenarios where multiple objects (of the same category) are present induce a pressure for generating names which uniquely identify the target \cite{olson1970language}, such that sub-level names can be systematically elicited in these cases \cite{rohde2012communicating,graf2016animal}.
For example, in presence of more than one dog, the name \textsl{dog} is ambiguous and a sub-level category (e.g., \textsl{rottweiler}, \textsl{beagle}) is more informative and potentially preferred by speakers, though additional factors such as cost or saliency also come into play \cite{graf2016animal,clark1983common}.

The purely taxonomic view has been criticized in more recent work on concept organization, which found that many objects of our daily lifes are part of multiple category systems at the same time \cite{ross1999food,SHAFTO20111}. 
This \textit{cross-classification} occurs, for instance, with food categories which can be taxonomy-based (e.g.\ \refexp{meat, vegetable}) or script-based (e.g.\  \refexp{breakfast, snack}).
We provide tentative evidence that cross-classification is indeed relevant for naming variation, and that the taxonomic axis is not the main parameter that accounts for variation in our data.

\subsection{Visual Object Recognition}

Visual object recognition studies object representations in the human visual system, (cf.\ \newcite{regan2000human,rossion2004revisiting}). 
An important experimental paradigm here is picture naming, where subjects have to say or write down the first name that comes to mind when looking at a picture of (typically) a line drawing depicting a prototypical instance of a category (\newcite{snodgrass}, see Figure\ \ref{fig:cake}).
Subjects reach very high agreement in this task \cite{rossion2004revisiting}, and the resulting naming norms are useful for studying various cognitive processes \cite{humphreys1988cascade}.
Our task is inspired by picture naming, but uses real-world images with objects highlighted in them.

Recognition of objects in images has also been the focus of Computer Vision, where state-of-the-art systems are now able to predict thousands of different categories (e.g.\ \newcite{googlenet}). 
Current recognition benchmarks use labels (and images) from the ImageNet \cite{imagenet_cvpr09} taxonomy, and typically assume a single ground-truth label.
% (e.g., for the young beagle case above, it would be the category \domain{beagle}).
In L\&V, deep object recognition systems are widely used for feature extraction, whereas the object labeling itself can often not be used directly. For instance, many labels in the ILSVRC  challenge \cite{ILSVRC15} correspond to very specific breeds of animals, whereas other common categories for,\ e.g.,\ people are missing.

\begin{table*}[htb]
  \centering
  \begin{tabular}{lrrrrr}
    \toprule
    &   RefCoco/+  &  Flickr30kE &           VG &      VGmn &        MN \\
    \midrule
    \# objects & 50.000 & 243.801 & 3.781.232 & 25.223 & 25.315 \\
    naming vocab size &  5.004 &  10.423 &   105.441 &  1.061 &  7.970 \\
    av. annotations/object &      2.8 &       2.3 &         1.7 &      7.2 &     35.3 \\
    \% objects with n types $>$ 1 &      0.7 &       0.3 &         0.02 &      0.1 &      0.9 \\
    av. types/object &      1.9 &       1.4 &         1 &      1.1 &      5.7 \\
    \bottomrule
  \end{tabular}
  \label{tab:compare}
  \caption{Overview statistics for different data sets containing object naming data. VGmn shows statistics for the subset of \vg that overlaps with our ManyNames dataset. \gbt{What is the VGmn column? Is it necessary?} \sz{VGmn refers to the subset of images in VG that appear in MN. This shows that the images we selected for ManyNames also have more annotations in VG. I think this is useful to know.} \gbt{ok! We'll need to explain why the number of objects not identical.}}
\end{table*}

\subsection{Hierarchical Object Categorization}

Some work in L\&V \cite{deng2014large,wang2014poodle,peterson2018learning} criticizes the use of single labels for object naming and categorization.
This line of research has emphasized the taxonomic organization of categories, following the seminal work on prototypes by \newcite{rosch1976basic} mentioned above.
These works propose granularity-aware object recognition methods, that incorporate the taxonomic structure underlying object labels in multi-label settings; for the ``young beagle'' example, labels \word{beagle}, \word{dog}, \word{animal} would all be considered valid.
Instead, other sources of variation like cross-classification have not received attention in L\&V.
As mentioned above, our results suggest that cross-classification occurs very frequently when naming objects in real-world images.

\subsection{Object Naming in L\&V} 

Work that models which \textbf{word} (as opposed to a category label) a speaker will use to name an object is relatively scarce.
Natural language generation has intensively investigated referring expressions~\cite{dale:1995,krahmer:2012}; however, this area has focused mostly on the selection of attributes, typically assuming that the name is given.
\gbt{Add example}
\newcite{Ordonez:2016} takes up the notion of entry-level categories and transfers an object's predicted label to its name.
Their model classifies objects into fine-grained categories (\gbt{e.g., ++++++ }), and then predicts a WordNet synset to retrieve the name (e.g., \word{swan}), based on frequencies in a text corpus.
This work assumes that \gbt{+++++complete please, stating what's different to ours}
 \newcite{zarriess-schlangen:2017} learn a naming model on referring expressions and real-world images, but focus on combining visual and distributional information. 
\gbt{I don't understand how this differs from other research and our own.}
Recent experimental work on reference found that the specificity of a name is dependent on the taxonomic relatedness of other objects in context
\cite{rohde2012communicating,graf2016animal}. 
However, this work studies a very limited set of images \gbt{+++++complete please, stating what's different to ours}
Our work is a first step towards studying naming in real-world, natural reference.
As there is virtually no existing large-scale resource that provides robust naming data elicited from multiple subjects \textit{and} for instances in real-world images, this paper focuses on naming in isolation, rather than reference where naming interacts with attribute selection.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "lrec2020naming"
%%% End:
