%
% File emnlp2019.tex
%
%% Based on the style files for ACL 2019, which were
%% Based on the style files for EMNLP 2018, which were
%% Based on the style files for ACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{emnlp-ijcnlp-2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}  %%% for including graphics
\usepackage{booktabs}
\usepackage{xspace}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand\confname{EMNLP-IJCNLP 2019}
\newcommand\conforg{SIGDAT}
\newcommand{\refexp}[1]{\textsl{#1}}
\newcommand{\word}[1]{\textsl{#1}}
\newcommand{\cat}[1]{\textsc{#1}}
\newcommand{\vgenome}{VisualGenome\xspace}
\newcommand{\ra}{$\rightarrow$}

\newcommand{\sz}[1]{\textcolor{blue}{\emph{//sz: #1//}}}
\newcommand{\gbt}[1]{\textcolor{orange}{\emph{//g: #1//}}}
\newcommand{\cs}[1]{\textcolor{green}{\emph{//cs: #1//}}}

\title{Do Objects in Real-World Images Have a Canonical Name?} 

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Research in language \& vision commonly acknowledges the fact that speakers can interpret and describe visual scenes in many different ways, cf.\ work on image captioning. 
%For instance, frameworks in image captioning  typically elicit (during collection) or train and test on (during modeling) multiple valid alternatives. 
Individual visual objects and their names, however, are usually modeled in simple annotation tasks where objects are labelled with a single canonical name. 
This typically rests on the assumption that linguistic variants of these canonical names that would occur in natural naming situations (e.g. when referring to an object) can be retrieved via their lexical relations in a taxonomy like WordNet.
%A prime example here is VisualGenome that features complex and varied annotations on the level of scenes and regions, but provides canonicalized objects linked to a single name. 
We put these assumptions 
%that objects in complex visual scenes bear a canonical name and that its possible alternatives can be easily retrieved from existing taxonomies t
to an empirical test and elicit multiple names (from 36 subjects) for objects annotated in VisualGenome.
%W investigate the extent to which there is variation in the names chosen by different people for the same object. Our
We find that our non-canonicalized object naming data shows decent agreement on the instance-level, but little agreement on the category-level, revealing a lot of variation with respect to how speakers name different objects of the same category.
When linking to WordNet, we observe that most of the alternatives for the original name in VisualGenome cannot be retrieved via hierarchical relations, as
more complex relations like cross-classification of objects, metonymy or variation due to visual uncertainty account for a major portion of the variation.
%different levels of specificity (cow-animal) or verbalize different aspect of the same object (bowl-salad). At the same time, we find that object naming prompted via bounding boxes is subject to a certain amount of noise as speakers have problems re-identifying the object that was annotated by the original bounding box. 
We investigate whether a state-of-the-art model of object labeling implicitly encodes similar variation in object naming and discuss implications for research in language \& vision.
\end{abstract}

\section{Introduction}
\input{intro}

%\section{Related Work}
%\label{sec:relwork}
%\input{relwork}

\section{Data collection}
%\label{sec:data}
%\input{data-collection}

\section{Analysis: Agreement}
\label{sec:analysis}
\input{analysis}

\section{Analysis: Taxonomy}
\label{sec:taxo}
\input{analysis2}


%\section{Modeling}
%\label{sec:modeling}

\section{Conclusions}
\label{sec:conc}

\bibliographystyle{acl_natbib}
\bibliography{naming}

%\appendix
%\section{Instructions for AMT Experiment}
%\label{app:instructions}
%\input{suppl_instructions}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
