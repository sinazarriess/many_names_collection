

\subsection{Experimental Setup}
\textbf{THIS IS VERY CRYPTIC}
\paragraph{Model}
We used \citeauthor{anderson2018updown}'s \citeyear{anderson2018updown} bottom-up attention model\footnote{The features code and data is available at \url{https://github.com/peteanderson80/bottom-up-attention}}. 
It uses Faster R-CNN in conjunction with the ResNet-101 CNN and was pretrained on object and attribute annotations from VisualGenome (after initialization with pretrained ImageNet model).
\iffalse
"To pretrain the bottom-up attention model, we first initialize Faster R-CNN with ResNet-101 pretrained for classification on ImageNet [35]. We then train on Visual
Genome [21] data. To aid the learning of good feature
representations, we add an additional training output for
predicting attribute classes (in addition to object classes).
To predict attributes for region i, we concatenate the mean
pooled convolutional feature vi with a learned embedding
of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each
attribute class plus a ‘no attributes’ class.
The original Faster R-CNN multi-task loss function contains four components, defined over the classification and
bounding box regression outputs for both the RPN and the
final object class proposals respectively. We retain these
components and add an additional multi-class loss component to train the attribute predictor"
\fi

\paragraph{Data}
\begin{itemize}
	\item We use the softmax distribution for the VG object names, and ignore the distribution over attributes. 
	\item The authors manually cleaned the set of object names to remove those with poor detection performance.
	\item Set of classes: 1,600 object names
	Overlapping classes, such as \textsl{person} and \textsl{guy}, were not merged to single classes. (For those cases, we therefore would expect that evaluating the model output on our set of names per instance to yield higher detection accuracy. )
	\item Image set and vocabulary: $XXX$~names are not in MN, i.e., our vocabulary (MN--VG) contains $XXX$~names. 
	We filtered out those images whose VG name was not found in MN--VG, which resulted in $24,585$~instances (note that of those $22,304$~images were also part of the training data of bottom-up)
\end{itemize} 

\paragraph{Measures}
\textsl{top}: the model's top prediction
\begin{itemize}
	\item \textbf{=VG} The average model accuracy of \textsl{top} on the VG names
	\item \textbf{=MN-1} The average model accuracy of \textsl{top} on the top response in ManyNames
	\item \textbf{$\in$MN} The average model accuracy of \textsl{top} to match any name of the responses in ManyNames
	\item \textbf{KL} The average Kullback-Leibler divergence~$\mathrm{D_{KL}}(M||S)$ of the model's softmax output~$S$ and the  probability distribution~$M$ over ManyNames, estimated by normalizing the name counts per instance
\end{itemize}


\paragraph{Results} 
We compare the model against a random baseline for the KL divergence, and against a most-frequent name baseline. 
We further compare the model on the set of instances where the VG names does not match the top response in MN (block \mbox{VG$\neq$MN-1} in Table~\ref{tab:model}), and to those which were not part of the set of images used for training bottom-up ($\neg$Training).
%
\begin{table*}
	\centering
	\small
\begin{tabular}{l@{~}|@{~}r@{~}r@{~}rr@{~}|@{~}r@{~}r@{~}rr@{~}|@{~}r@{~}r@{~}rr}
	\toprule
	%{} &  All images-top=VG &  All images-top=MN-1 &  All images-top\$\textbackslash in\$MN &  All images-KL &  VGnotMN-top=VG &  VGnotMN-top=MN-1 &  VGnotMN-top\$\textbackslash in\$MN &  VGnotMN-KL &  notTrain-top=VG &  notTrain-top=MN-1 &  notTrain-top\$\textbackslash in\$MN &  notTrain-KL \\
		& \multicolumn{12}{c}{Image subset} \\
		&	\multicolumn{4}{c}{All ($24,585$)} 
		& \multicolumn{4}{c}{VG$\neq$MN-1 ($6,280$)}
		& \multicolumn{4}{c}{$\neg$Training ($2,281$)} \\
	\midrule
		Domain	 &  =VG & =MN-1 & $\in$MN  &  KL
		&  =VG & =MN-1 & $\in$MN  & KL
		&  =VG & =MN-1 & $\in$MN  & KL\\
\midrule
all            &               68.7 &                 76.8 &                   94.8 &            0.9 &            20.7 &              52.6 &                92.4 &         1.2 &             63.5 &               73.1 &                 92.5 &          1.0 \\ \\
home           &               70.0 &                 74.7 &                   93.4 &            1.1 &            24.3 &              47.5 &                91.4 &         1.4 &             67.2 &               70.5 &                 92.5 &          1.2 \\
food           &               60.0 &                 71.9 &                   87.7 &            1.0 &            14.2 &              48.9 &                76.6 &         1.5 &             46.6 &               62.1 &                 80.1 &          1.3 \\
buildings      &               57.5 &                 70.7 &                   92.1 &            1.3 &             7.9 &              63.4 &                89.8 &         1.5 &             44.3 &               60.2 &                 88.6 &          1.4 \\
vehicles       &               69.8 &                 72.8 &                   97.6 &            0.6 &            35.3 &              46.1 &                97.4 &         0.7 &             67.2 &               73.5 &                 96.4 &          0.7 \\
animals/plants &               92.7 &                 94.8 &                   97.7 &            0.4 &            20.3 &              65.0 &                94.0 &         0.9 &             91.3 &               92.6 &                 96.2 &          0.5 \\
clothing       &               63.3 &                 70.9 &                   92.6 &            1.0 &            19.9 &              48.5 &                90.3 &         1.2 &             50.8 &               60.2 &                 87.4 &          1.3 \\
people         &               48.5 &                 70.7 &                   95.5 &            1.2 &            13.8 &              58.9 &                95.3 &         1.3 &             42.2 &               68.2 &                 92.8 &          1.2 \\
\bottomrule
%Baseline      &                3.3 &                  5.2 &                   12.0 &            -- &             1.7 &               9.3 &                21.8 &         -- &              3.0 &                5.0 &                 11.9 &          -- \\
Baseline       &                3.9 &                  4.6 &                    5.6 &            -- &             0.1 &               3.0 &                 3.8 &         -- &              3.8 &                4.6 &                  5.8 &          -- \\
\end{tabular}
\caption{Baseline: The most frequent name. Random baseline (KL with random distributions) for each image set: 6.9 (all), 6.5 (VG$\neq$MN-1) and 6.9 ($\neg$Training)	\label{tab:model}}
\end{table*}


